---
title: "Gossiping Text Mining"
author: "楊博儒"
output: html_document
---

# 八卦版文字探勘

本次文字探勘所使用的資料為 PTT 八卦版在 2019 年二月和三月的所有貼文和推文的資料。

PTT 八卦版上有許多關於不同議題的討論，在一定程度上能夠代表 25 到 40 歲年齡層的意見。而在這個平台之上，透過將不同的議題適當地分類，可以反映出不同時刻下的熱門話題，也能夠找出對於八卦版使用者而言，哪些議題得到較多的關注，而哪些議題只受到部分使用者的討論。

因此在這次的文字探勘中，我試圖回答幾個問題：

- 在八卦版的文章當中，可以分出哪些明顯的主題？
- 這些不同主題的文章在這兩個月的時間內，貼文的熱度是否有變化？
- 哪些主題的文章是 PTT 使用者偏好的推文主題？
- 哪些主題的推文者只偏好回覆單一主題的文章？

```{r setup, message=FALSE}
options(stringsAsFactors = FALSE)
library(tidyverse)
library(jiebaR)
library(LDAvis)
library(servr)
library(tidytext)
library(igraph)
library(topicmodels)
library(ade4)
```

### 讀取八卦版資料
```{r data, message=FALSE}
load("Ptt_gos_feb_post.rda")
load("Ptt_gos_mar_post.rda")
allpost <- bind_rows(Ptt_gos_feb_post, Ptt_gos_mar_post)

load("Ptt_gos_feb_reply.rda")
load("Ptt_gos_mar_reply.rda")
allreply <- bind_rows(Ptt_gos_feb_reply, Ptt_gos_mar_reply)
```

### 引用斷詞和字典
```{r jieba, message=FALSE}
segment_not <- c("蔡英文", "蔡總統",  "韓國瑜", "柯文哲", "柯市長", "柯p", "韓市長", "九二共識", "空污", "高雄", "韓粉", "喜韓兒", "藍蛆", "綠吱", "時代力量", "舔共", "假新聞", "笑死", "歐陽娜娜", "爆料公社", "核電", "劈腿", "非洲豬瘟", "比特犬", "屏東燈會")
stopWords <- readRDS("stopWords.rds")
stopWords <- rbind(stopWords, data.frame(word = c("1.", "2.", "from", "my", "Sent", "JPTT", "完整", "連結", "網址", "內文", "備註", "來源", "3.", "4.", "5.", "新聞標題", "約", "達", "占", "G", "the", "a", "to", "in", "I", "and", "of", "s", "is", "you", "IPhone", "Asus", "ASUS", "Samsung", "SM", "Sony", "HTC", "u", "Xiaomi")))

jieba <- worker()
new_user_word(jieba, segment_not)
```

## 在八卦版的文章當中，可以分出哪些明顯的主題？

我使用 LDA 主題模型，根據貼文的內文來找出潛在不同的主題，預設有 25 個不同主題。

### 主題模型資料前處理
```{r, message=FALSE}
allpost <- allpost %>%
  mutate(doc_id = row_number())

allpost$doc_id <- as.character(allpost$doc_id)

allpost_tokenized <- allpost %>%
  select(post, doc_id) %>%
  mutate(word = purrr::map(post, function(x) segment(x, jieba))) %>%
  unnest(word) %>%
  anti_join(stopWords) %>%
  mutate(word = gsub("[A-Za-z0-9]", "", word)) %>%
  filter(nchar(word) > 1) %>% 
  count(doc_id, word, sort = TRUE) %>%
  ungroup()
```

### 創造 document_term matrix 並且套入 LDA 模型
```{r, message=FALSE}
allpost_dtm <- allpost_tokenized %>% cast_dtm(doc_id, word, n)

ldaOut <- LDA(allpost_dtm, 25, method="Gibbs", control=list(seed = 1234))
```

### 將 LDA 模型視覺化
```{r, message=FALSE}
topicmodels2LDAvis <- function(x, ...){
    post <- topicmodels::posterior(x)
    if (ncol(post[["topics"]]) < 3) stop("The model must contain > 2 topics")
    mat <- x@wordassignments
    LDAvis::createJSON(
        phi = post[["terms"]], 
        theta = post[["topics"]],
        vocab = colnames(post[["terms"]]),
        doc.length = slam::row_sums(mat, na.rm = TRUE),
        term.frequency = slam::col_sums(mat, na.rm = TRUE)
    )
}

lda.json <- topicmodels2LDAvis(ldaOut)
serVis(lda.json, out.dir = 'vis', open.browser = FALSE)
```

視覺化結果：https://boruyang.github.io/CSX-4001/gossiping_text_mining/vis/

根據結果可以看出所有的文章都被分成了 25 種不同的主題，在不同的主題之下可以觀察到前 30 個最相關的詞彙。上面有 lambda 參數可供調整，當 lambda 為 1 的時候，呈現的前 30 個詞彙是完全根據出現的次數來排序，若把 lambda 值調小，會使得 document-specific 的用詞的權重被提高，也就是會使得一些整體來說出現頻率不那麼高，但是在某一類主題中特別關鍵的詞彙也排進前 30 個相關詞彙。

透過這張視覺化的圖表，便能夠對不同的主題做歸類，然而在這張視覺化的圖中，它因為有自己分派主題的方式（佔比例最大的主題為主題 1，次之的為主題 2 佔比最小的為主題 25），導致圖中的主題分類號碼和實際的主題分類號碼是不一樣的，因此我們必須要列出圖中的主題對照到實際的哪個主題，而該主題又是說明什麼。

- 視覺化主題號碼 = 實際主題號碼 主題名稱
- top 1 = 16 中美相關議題
- top 2 = 18 市場投資議題
- top 3 = 24 總統初選
- top 4 = 14 理性討論
- top 5 = 13 兩岸議題
- top 6 = 17 交通事故
- top 7 = 8 同婚能源法案
- top 8 = 25 過年時節活動
- top 9 = 4 柯文哲
- top 10 = 21 歷史宗教議題
- top 11 = 23 各國國防議題
- top 12 = 20 遊戲與還願
- top 13 = 22 華航罷工
- top 14 = 5 網路相關新聞
- top 15 = 2 憤怒討論
- top 16 = 6 刑事案件新聞
- top 17 = 10 醫療與非洲豬瘟
- top 18 = 9 韓國瑜
- top 19 = 19 廢文
- top 20 = 1 家庭和感情
- top 21 = 3 房屋與房價
- top 22 = 11 台大醫學系八卦
- top 23 = 7 廢文
- top 24 = 12 廢文
- top 25 = 15 廢文

以上所呈現的就是在 PTT 八卦版中 2019 年二月到三月中重要的主題。

## 這些不同主題的文章在這兩個月的時間內，貼文的熱度是否有變化？

在找出了不同的主題之後，接下來就必須把這些主題分派回文件，並且把時間的變項納入進行分析。

這裡要提到 LDA 主題模型有一個特色，由於它是利用貝氏統計的概念來進行分類，因此一份文件屬於哪一個主題並不是被很武斷地分類出來的結果，而是會計算出一份文件屬於不同主題的機率各是多少。我們要找出其中最大機率的分類，並以此分類來作為該文件的主題。

在這樣的思維之下，如果一份文件的內容非常切合到特定主題，那麼他被分配到該主題的機率就會很大，分配到其他主題的機率就會很小。若存在一份文件其實都不太適合先前已經分類出來的大主題，那該文件之於不同主題的機率分配，就會相當均勻並且機率值都不會很大。

站在想要探討議題熱度的角度思考，會希望分析的文件能夠被明確分到特定主題，因此我在這個階段資料前處理的部分，找出每一個文件最有可能被分配到的主題，並將該主題指派回該文件，再剔除掉主題最大機率分類小於 0.2 的文件（因為這些文件通常不適合已經分類出來的主題）。

### 主題分類資料前處理
```{r, message=FALSE}
topic_distribution <- tidy(ldaOut, matrix = "gamma")

topic_classification <- topic_distribution %>%
  group_by(document) %>%
  top_n(1, gamma) %>%
  filter(gamma > 0.2) %>%
  ungroup()

topic_classification <- 
  topic_classification[!duplicated(topic_classification$document), ]

colnames(topic_classification)[1] <- "doc_id"

post_with_topic <- topic_classification %>%
  select(-gamma) %>%
  left_join(allpost, by = "doc_id") %>%
  mutate(topic_name = ifelse(topic == 16, "中美相關議題",
                      ifelse(topic == 18, "市場投資議題",
                      ifelse(topic == 24, "總統初選",
                      ifelse(topic == 13, "兩岸議題",
                      ifelse(topic == 17, "交通事故",
                      ifelse(topic == 8, "同婚能源法案",
                      ifelse(topic == 25, "過年時節活動",
                      ifelse(topic == 4, "柯文哲",
                      ifelse(topic == 21, "歷史宗教議題",
                      ifelse(topic == 23, "各國國防議題",
                      ifelse(topic == 20, "遊戲與還願",
                      ifelse(topic == 22, "華航罷工",
                      ifelse(topic == 5, "網路相關新聞",
                      ifelse(topic == 2 , "憤怒討論",
                      ifelse(topic == 14, "理性討論",
                      ifelse(topic == 6, "刑事案件新聞",
                      ifelse(topic == 10, "醫療與非洲豬瘟",
                      ifelse(topic == 9, "韓國瑜",
                      ifelse(topic == 1, "家庭和感情",
                      ifelse(topic == 3, "房屋與房價",
                      ifelse(topic == 11, "台大醫學系八卦", "廢文"))))))))))))))))))))))
```

### 熱度趨勢圖資料前處理
```{r, message=FALSE}
post_with_topic_plot <- post_with_topic %>%
  select(topic_name, timestamp) %>%
  mutate(timestamp = str_replace(timestamp, "  ", " ")) %>%
  separate(timestamp, c("day", "month", "date", "time", "year"), sep = " ") %>%
  mutate(date = as.numeric(date)) %>%
  mutate(week = ifelse(month == "Feb" & date <= 7, "Feb w1",
                ifelse(month == "Feb" & date <= 14, "Feb w2",
                ifelse(month == "Feb" & date <= 21, "Feb w3",
                ifelse(month == "Feb" & date <= 28, "Feb w4",
                ifelse(month == "Mar" & date <= 7, "Mar w1",
                ifelse(month == "Mar" & date <= 14, "Mar w2",
                ifelse(month == "Mar" & date <= 21, "Mar w3", "Mar w4")))))))) %>%
  group_by(topic_name, week) %>%
  count(topic_name) %>%
  filter(!is.na(week)) %>%
  ungroup() %>%
  group_by(week) %>%
  mutate(proportion = n / sum(n))
```

### 作出貼文熱度趨勢圖
```{r}
color25 <- c("dodgerblue2","#E31A1C", # red
                "green4",
                "#6A3D9A", # purple
                "#FF7F00", # orange
                "black","gold1",
                "skyblue2","#FB9A99", # lt pink
                "palegreen2",
                "#CAB2D6", # lt purple
                "#FDBF6F", # lt orange
                "gray70", "khaki2",
                "maroon","orchid1","deeppink1","blue1","steelblue4",
                "darkturquoise","green1","yellow4","yellow3",
                "darkorange4","brown")

ggplot(post_with_topic_plot, aes(x = week, y = proportion, fill = topic_name)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = color25, name = "topic") +
  ggtitle("PTT 八卦版二月到三月討論熱度趨勢圖") +
  theme(text = element_text(family = "PingFangTC-Medium"))
```

根據這張趨勢圖，可以發現以下有趣的現象：

- 總統初選整體來說到了三月討論風氣更盛，在三月第三周尤其受到關注（賴清德說要參加初選）。
- 開學前後是台大醫學系八卦討論最熱烈的時期。
- 兩岸議題也是到三月討論較多，總統初選議題熱完之後換兩岸議題熱度上升。
- 過年期間華航罷工議題突然受到高度關注。
- 韓國瑜和柯文哲熱度差不多，長期趨勢也算穩定。
- 廢文穩定佔了滿大比例...

## 哪些主題的文章是 PTT 使用者偏好的推文主題？

除了探討不同主題的熱度之外，我們也會想要知道哪些主題更容易吸引到使用者來回應，透過網路圖的呈現，可以清楚看出哪些主題的文章處於網路結構的中心（代表是大多數人會回應的文章主題），哪些類型的文章落在網路結構的邊陲，哪些文章因為性質相同而聚集在一起。

### 網絡圖資料前處理
```{r, message=FALSE}
reply_with_topic <- post_with_topic %>%
  select(url, topic_name) %>%
  left_join(allreply, by = "url") %>%
  select(topic_name, id)

edge_list <- reply_with_topic %>%
  select(id, topic_name) %>%
  group_by(id, topic_name) %>%
  count(id) %>%
  filter(n >= 8) %>%
  group_by(id, topic_name) %>%
  count(id) %>%
  select(id, topic_name)

g_item <- graph.data.frame(edge_list, directed = FALSE)
V(g_item)$type <- bipartite_mapping(g_item)$type
bipartite_matrix <- as_incidence_matrix(g_item)
topic_net <- dist.binary(t(bipartite_matrix), method = 2, upper = TRUE, diag = FALSE)
topic_net <- as.matrix(topic_net)
topic_net <- ifelse(topic_net > 0.5, 1, 0)
```

### 作出網絡圖
```{r}
netgraph <- graph.adjacency(topic_net, mode = "undirected", weighted = TRUE, diag = FALSE)
closeness <- closeness(netgraph, mode = "all")
set.seed(1234)
par(family = ("PingFangTC-Medium"))
plot(netgraph, vertex.size = closeness*600-5, vertex.label.cex = closeness*15, vertex.label.family = "PingFangTC-Medium", main = "PTT 八卦版二月到三月主題網路圖", sub = "節點大小代表 closeness centrality 的大小")
```

根據這張網路圖，可以發現普遍使用者最喜歡回復的文章類型為「柯文哲、韓國瑜、總統初選、兩岸議題」，這四個節點群聚在一塊，顯示出他們有很類似的特性，除了都是政治類型的文章外，四者都有相對較多的推文數，並且都有較高的接近中心性(closeness centrality)，代表這四個主題因為本身推文數多的關係，相對較容易和其他主題產生關聯（此處的關聯為不同主題收到同一使用者的推文）。

除了最中間形成了一個群聚之外，網路圖的下方也有一塊較小的群聚，相關的節點包括討論類和新聞類的主題，顯示出這些主題之間的性質相近，同一個使用者也經常同時在這些類別的主題之下回復。

## 貼文熱度和推文網路結構的關係

我們先前探討了文章熱度和推文網路結構，接下來我們有興趣的問題是，文章熱度和推文網路結構所反映出來的情況是否一致，也就是貼文熱度高的主題是否意味著就是使用者偏愛回復的主題。

### 畫出不同主題文章整體則數
```{r}
comparison <- post_with_topic_plot %>%
  select(topic_name, n) %>%
  group_by(topic_name) %>%
  mutate(sum = sum(n)) %>%
  filter(!duplicated(topic_name))

ggplot(comparison) +
  aes(x = reorder(topic_name, sum), y = sum) +
  geom_bar(stat = "identity") +
  coord_flip() +
  xlab("topic") +
  ylab("則數") +
  ggtitle("PTT 八卦版二月到三月貼文主題則數") +
  theme(text = element_text(family = "PingFangTC-Medium"))
```

透過觀察上圖可以發現，貼文熱度和推文網路結構之間存在些許的出入，貼文主題則數最高的主題「廢文」出現在網路結構的邊陲地帶，而貼文主題則數第二和第三的主題「兩岸議題、總統初選」才出現在推文網路結構的核心區塊。

根據這個現象，可以推論 PTT 八卦版的「廢文」主題的貼文熱度並不能真正代表這個主題受關注的程度，因為這類的文章只是被發佈得很多，實際獲得的回應卻很少。在八卦板中真正受到討論的主題是在貼文熱度上夠高，推文網路結構上也具有中心性的主題，也就是和總統初選和兩岸議題相關的主題。

## 哪些主題的推文者只偏好回覆單一主題的文章？

我們先前畫出了 PTT 推文者的推文網路圖來找出哪些主題是更容易受到回復的主題，最後我們想要知道哪些主題的推文者只偏好回覆單一主題的文章。透過解析這個問題，可以進一步瞭解到那些能夠在網路結構中佔據中心位置的主題，是因為受到普遍使用者的關注，或者是存在一群只會對這類主題進行推文的使用者，這個問題也可以幫助我們釐清不同主題自身的特性，並且去推論不同主題之所以得到較多的關注，背後的成因是否存在差異。

### 單一推文者資料前處理
```{r , message=FALSE}
uniuser <- as.data.frame(bipartite_matrix) %>%
  mutate(sum = rowSums(.[1:22])) %>%
  filter(sum <= 2) %>%
  summarise_at(vars(1:22), sum)

topic_weighted_net <- t(bipartite_matrix) %*% bipartite_matrix
all_replier <- diag(topic_weighted_net)
uni <- uniuser/all_replier
uni <- gather(uni, topic, proportion, 1:22)
```

### 呈現不同主題單一推文者的比例
```{r}
ggplot(uni) +
  aes(x = reorder(topic, proportion), y = proportion) +
  geom_bar(stat = "identity") +
  coord_flip() +
  xlab("topic") +
  ylab("proportion") +
  ggtitle("PTT 八卦版二月到三月各單一主題推文者比例") +
  theme(text = element_text(family = "PingFangTC-Medium"))
```

根據上面這張圖，可以看到單一主題推文者比例最高的主題是華航罷工，再來是韓國瑜以及廢文，華航罷工的推文者中，有高達三成的人在這兩個月的時間中，只對一種到兩種的文章主題進行推文，這樣的人在韓國瑜以及廢文的推文者中也佔了大約兩成。雖然這三類主題相對於其他主題都有較高比例的單一主題推文者，然而我認為這種現象背後的成因是不一樣的。

華航罷工的高比例單一主題推文者，搭配上貼文熱度在二月第二週快速竄起（達到總體推文的四分之一）之後又快速消退，呈現出該主題在當時吸引了很多潛水客（只看文不推文）的回復，這些人看到這種和勞動權益相關的大型事件，認為必須出來發聲，故很難得地進行推文，導致這類主題的文章擁有最高的單一主題推文者比例。

廢文擁有將近兩成的單一主題推文者，搭配上穩定的貼文熱度，貼文數量為最高，推文網路中卻處於邊陲位置的事實，不難看出廢文的主題雖然不是大部分使用者偏愛回復的文章，卻存在有一批使用者在 PTT 上不回復其他類型的文章，而僅僅偏愛回復貼文數最多且穩定產生的廢文。（我猜回復這種沒營養的文章可能是某些人的生活樂趣）

韓國瑜擁有大於兩成的單一主題推文者，搭配上穩定的貼文熱度，高貼文數量，推文網路中也處於中心位置的事實，我認為背後的成因可能是韓國瑜相關的主題和新聞在這兩個月的時間內持續出現大大小小的爆點，不同的爆點能夠有效吸引不同潛水客的回復，另外也存在一群對於政治相關議題有關注 PTT 使用者長期在這類主題上面推文，因而同時出現了在推文網路中佔有重要位置和高比例單一主題推文者兩個看似矛盾的性質。

市場投資議題和過年時節活動有最低比例的單一主題推文者，代表這兩類主題推文者的多元性最高，所吸引到的推文者通常在其他類型主題也會推文。

## 結論

透過 LDA 模型我們找出了在 PTT 八卦板中特別受到討論的幾個主題，並且我們試圖去找出不同主題受到關注的程度為何。我們理解主題受關注的程度，切入的面向包括貼文熱度、貼文總則數、推文網路結構和推文者單一程度，透過綜觀這些不同的指標，才有辦法正確理解不同主題如何被 PTT 使用者看待。以下特別提出幾個較有特色的主題進行說明：

- 華航罷工主題：華航罷工相關的討論在本次的資料中，貼文熱度竄起速度最快，成為一週內最熱門的主題，並且在事件結束後快速消退。在推文網路結構中的重要性也僅次於群聚在結構中央的四個政治相關主題，並且擁有最高的單一推文者比例。以上這些指標顯示出在相關事件爆發之後，這個議題立即受到 PTT 使用者最大程度的關注，甚至召喚出了許多平常在 PTT 上不會推文的使用者的聲援。

- 政治相關主題：政治相關的主題包含「柯文哲、韓國瑜、兩岸議題、總統初選」，這四個主題除了總統初選越來越熱門之外，都有相當穩定的貼文熱度，而這些主題也相當緊密地群聚在推文網路結構的中心，呈現出它們不僅在議題的方向上接近，並且都是 PTT 使用者特別偏愛回應的主題。

- 韓國瑜：在政治相關的四個主題中我們特別拉出韓國瑜的主題進一步探討，因為這個主題在推文結構上處於重要的位置，卻也擁有相當高比例的單一主題推文者。這個現象顯示出雖然韓國瑜和其他政治相關主題的文章都同為 PTT 使用者較為偏好的推文主題，但是韓國瑜主題的推文者在推文的行為上單一的程度較高，也就是說韓國瑜主題有較高比例的推文者就只會回應韓國瑜的主題，這背後所代表的意涵是該主題能夠不斷地吸引到不同的潛水客推文，同時又有一大批本來就很關注政治議題的使用者推文。

- 廢文：廢文在 PTT 的推文熱度相當穩定，並且擁有最高的推文則數，在推文網路結構中卻處於相當邊緣的位置，也有較高的單一主題推文者比例，顯示出這類文章在 PTT 上只是被發布得很多，實際上大部份的 PTT 使用者對這樣主題並不是很有興趣，但即便如此，廢文主題仍存在著一批它自己的擁護者，在推文的行為上只會對這類主題進行推文。

以上是對幾個特別具有特色的主題分類進行簡要分析，在推文行為的部分目前是透過網路結構和單一推文者比例的指標來觀察，未來也許可以進一步去分析推文的內文並且搭配情感分析，進一步 PTT 使用者對於不同的主題所抱持的態度為何。
